{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Streaming ###\n",
    "\n",
    " * Data is generated continuously from one or many sources\n",
    " * Sources typically send in data simultaneously\n",
    " * Data comes in small packages (kilobyte scale) in succesiion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use Streaming ? \n",
    "\n",
    " * A lot of applications use continuously-updated data\n",
    " * Examples :\n",
    "     * Sensors in vehicles, industrial equipment, and machinery send data to streaming for performance measurement. -- IOT\n",
    "     * A website tracking geo-location data from customers' phones, which is gathered by streaming, so the website can make recommendations of which restaurants to visit.\n",
    "     * Solar power company monitoring panel performance through streaming.\n",
    "     * Online gaming compnay collecting streaming data about player-game interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular Streaming Tools ###\n",
    "\n",
    " * Storm \n",
    " * Flink : focused on distributed computation than streaming\n",
    " * Kinesis : Amazon ; not free\n",
    " * Samza : \n",
    " * Kafka :  \n",
    "     * reliability with handling terrabtype sclaed data\n",
    "     * automaticcly balances data consumers should any part of the system fail.\n",
    " * Apache Spark : useful for high velocity data streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Apache Spark Streaming ?\n",
    "\n",
    " * Spark is general purpose and is widely used.\n",
    " * Spark connects with a lot of the previously mentioned streaming tools (ex. Kafka)\n",
    " * Fault tolerant thanks to projects like Hadoop Distributed File System(HDFS)\n",
    " \n",
    "Spark is the cluster computing framework maintained by the Apache Software Foundation. \n",
    "Spark uses the data format, RDD(resilient Distributed Datasets). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='Spark_Image.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark can use products like above to make sure that some of these RDD can be recovered if some part of this network fails. So, Spark is also known as a fault tolerant due to being tolerant to some park of network failing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Core is at the center of this product and it deals with all these RDDs. Spark core handles all the basics file io, task scheduling.\n",
    "\n",
    "But there're four components top of it. They are 'Spark SQL', 'Spark Streaming', 'MLlib', 'GraphX'(handy tool for working with Graph databases)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
